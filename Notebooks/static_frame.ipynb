{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 24)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "#test_action = np.load('../Data/test_action.npy') \n",
    "#test_script = np.load('../Data/test_action.npy') \n",
    "\n",
    "init_pose = scio.loadmat('../Data/mean_pose.mat')['mean_vector']\n",
    "init_pose = np.transpose(init_pose,(1,0))\n",
    "init_input = tf.tile(tf.expand_dims(init_pose, axis=0), [1, 1, 1])\n",
    "print(init_input.shape)\n",
    "\n",
    "model_path = '../2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "def load_encoder(model_path):\n",
    "    #Output's dimension = 512\n",
    "    encoder = hub.load(model_path)\n",
    "    return encoder\n",
    "\n",
    "encoder = load_encoder(model_path)\n",
    "generator = tf.keras.models.load_model(\"../Models/model_epoch_150.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_joint3D(plot_vec):\n",
    "    plot_vec = np.reshape(plot_vec, [8, 3, -1])\n",
    "\n",
    "    mean_len = [0.6, 0.7, 0.9, 0.9, 0.7, 0.9, 0.9]\n",
    "\n",
    "    plot_pose = np.zeros(plot_vec.shape)\n",
    "    plot_pose[1, :, :] = plot_vec[0, :, :];\n",
    "    plot_pose[0, :, :] = plot_pose[1, :, :]+\\\n",
    "                         mean_len[0] * np.divide(plot_vec[1, :, :], \n",
    "                                                 np.tile(np.linalg.norm(plot_vec[1, :, :], axis=0), (3, 1)))\n",
    "    plot_pose[2, :, :] = plot_pose[1, :, :]+\\\n",
    "                         mean_len[1] * np.divide(plot_vec[2, :, :], \n",
    "                                                 np.tile(np.linalg.norm(plot_vec[2, :, :], axis=0), (3, 1)))\n",
    "    plot_pose[3, :, :] = plot_pose[2, :, :]+\\\n",
    "                         mean_len[2] * np.divide(plot_vec[3, :, :], \n",
    "                                                 np.tile(np.linalg.norm(plot_vec[3, :, :], axis=0), (3, 1)))\n",
    "    plot_pose[4, :, :] = plot_pose[3, :, :]+\\\n",
    "                         mean_len[3] * np.divide(plot_vec[4, :, :], \n",
    "                                                 np.tile(np.linalg.norm(plot_vec[4, :, :], axis=0), (3, 1)))\n",
    "    plot_pose[5, :, :] = plot_pose[1, :, :]+\\\n",
    "                         mean_len[4] * np.divide(plot_vec[5, :, :], \n",
    "                                                 np.tile(np.linalg.norm(plot_vec[5, :, :], axis=0), (3, 1)))\n",
    "    plot_pose[6, :, :] = plot_pose[5, :, :]+\\\n",
    "                         mean_len[5] * np.divide(plot_vec[6, :, :], \n",
    "                                                 np.tile(np.linalg.norm(plot_vec[6, :, :], axis=0), (3, 1)))\n",
    "    plot_pose[7, :, :] = plot_pose[6, :, :]+\\\n",
    "                         mean_len[6] * np.divide(plot_vec[7, :, :], \n",
    "                                                 np.tile(np.linalg.norm(plot_vec[7, :, :], axis=0), (3, 1)))\n",
    "    \n",
    "    # plot the virtal central_hip, left hip, right hip\n",
    "    v2h = np.array([plot_pose[2, 0, :],plot_pose[2, 1, :], plot_pose[2, 2, :]-1.5])\n",
    "    v5h = np.array([plot_pose[5, 0, :],plot_pose[5, 1, :], plot_pose[5, 2, :]-1.5])\n",
    "    \n",
    "    pelvis = (v2h+v5h)/2\n",
    "    pelvis = np.expand_dims(pelvis, axis=0)\n",
    "    plot_pose = np.concatenate([plot_pose, pelvis])\n",
    "    return plot_pose\n",
    "\n",
    "def draw_static_frames(plot_pose, save_path):\n",
    "    num_frames = plot_pose.shape[2]\n",
    "    cols = num_frames\n",
    "    rows = 1\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(rows, cols, subplot_kw={'projection': '3d'}, figsize=(16, 4 * rows))\n",
    "    axes = axes.ravel()  # Flatten axes for easy iteration\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Plot lines and points for the current frame\n",
    "        ax.plot(plot_pose[0:2, 0, i], plot_pose[0:2, 1, i], plot_pose[0:2, 2, i], c='black')\n",
    "        ax.plot(plot_pose[1:3, 0, i], plot_pose[1:3, 1, i], plot_pose[1:3, 2, i], c='black')\n",
    "        ax.plot(plot_pose[2:4, 0, i], plot_pose[2:4, 1, i], plot_pose[2:4, 2, i], c='black')\n",
    "        ax.plot(plot_pose[3:5, 0, i], plot_pose[3:5, 1, i], plot_pose[3:5, 2, i], c='black')\n",
    "        ax.plot(plot_pose[1:6:4, 0, i], plot_pose[1:6:4, 1, i], plot_pose[1:6:4, 2, i], c='black')\n",
    "        ax.plot(plot_pose[5:7, 0, i], plot_pose[5:7, 1, i], plot_pose[5:7, 2, i], c='black')\n",
    "        ax.plot(plot_pose[6:8, 0, i], plot_pose[6:8, 1, i], plot_pose[6:8, 2, i], c='black')\n",
    "\n",
    "        ax.scatter(plot_pose[:, 0, i], plot_pose[:, 1, i], plot_pose[:, 2, i], c='black')\n",
    "\n",
    "        # Remove grid, ticks, and labels\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_zticks([])\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_zlabel('')\n",
    "        ax.view_init(azim=0, elev=0)\n",
    "        ax.set_title(f'Frame {i}')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(num_frames, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    # Save the grid of static frames to a PDF file\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = np.random.randint(0, test_action.shape[0], 1)\n",
    "case_number = 5\n",
    "model_epoch = 150\n",
    "latent_dim = 20\n",
    "save_Real_path = f\"../Hyperparameter_Tuning_and_Ablation_Study/Model_and_Results/Case_{case_number}/static_Real_1_frame_1.png\"\n",
    "save_Fake_path = f\"../Hyperparameter_Tuning_and_Ablation_Study/Model_and_Results/Case_{case_number}/static_Fake_1_frame_1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = -0.13500924408435822\n",
    "max = 0.1370220184326172\n",
    "\n",
    "# Normalize action data\n",
    "def normalize_data(data, data_min, data_max):\n",
    "    return 2 * ((data - data_min) / (data_max - data_min)) - 1\n",
    "\n",
    "# Input: raw text\n",
    "# Output: (time_seq, 24) \n",
    "def gen_t2a(test_script, init_pose):\n",
    "\n",
    "    text_embeddings = encoder([test_script])\n",
    "    test_script_normalize = normalize_data(text_embeddings, min, max)\n",
    "\n",
    "    noise = tf.random.normal([1,latent_dim])\n",
    "    generated_motion = generator.predict([noise,test_script_normalize,init_pose])\n",
    "\n",
    "    return generated_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n"
     ]
    }
   ],
   "source": [
    "text_description = 'A woman is exercising in the gym room.'\n",
    "\n",
    "generated_motion = gen_t2a(test_script = text_description , init_pose= init_input)\n",
    "np.save(\"exercising_motion.npy\", generated_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific timeframes: 0, 4, 8, 12, 16, 20, 24, 28, 31\n",
    "selected_frames = [0, 12, 24,31]\n",
    "\n",
    "generated_motion = np.transpose(generated_motion,(0,2,1))\n",
    "\n",
    "# Filter the real_motion_transpose and generated_motion to only include selected frames\n",
    "#real_motion_filtered = real_motion_transpose[:, :, selected_frames]\n",
    "generated_motion_filtered = generated_motion[:, :, selected_frames]\n",
    "\n",
    "# Reconstruct the joint 3D positions for the filtered frames\n",
    "#real_action_filtered = construct_joint3D(real_motion_filtered)\n",
    "fake_action_filtered = construct_joint3D(generated_motion_filtered)\n",
    "\n",
    "# Draw Real and Fake motion for the selected frames\n",
    "#draw_static_frames(real_action_filtered, save_Real_path)\n",
    "draw_static_frames(fake_action_filtered, save_Fake_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
